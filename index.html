<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Barret Zoph</title>
  
  <meta name="author" content="Irwan Bello">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Barret Zoph</name>
              </p>
              <p>
                I'm a Staff Research Scientist at <a href="https://research.google/teams/brain/"> Google Brain</a>. I am current running a resesearch team working on various research ideas related to large language models.
								<HR>
              </p>
              <p>
								My current research focus is making large scale language models more efficient through a variety of methods such as sparsity and improved distributed partitioning algorithms
								[<a href="https://arxiv.org/abs/2101.03961">Switch Transformer</a>, <a href="">Improving General Distributed Sparsity</a>]. 
								<br>
								<br>
								I also work on a variety of topics in computer vision: multi-task learning for structured prediction 
								[<a href="https://arxiv.org/abs/2108.11353">MuST</a>], semi-supervised and data augmentation methods [<a href="https://arxiv.org/abs/2006.06882">Rethinking</a>, <a href="https://arxiv.org/abs/1805.09501">AutoAugment</a>, 
									<a href="https://arxiv.org/abs/1909.13719">RandAugment</a>, <a href="https://arxiv.org/abs/2012.07177">Copy-Paste</a>] and simple baselines [<a href="https://arxiv.org/abs/2103.07579">ResNet-RS</a>, 
										<a href="https://arxiv.org/abs/2107.00057">Detection-RS</a>].
								<br>
								<br>
								At Google Brain I was a research TL for <a href="https://blog.google/products/search/introducing-mum/">MuM</a>. 
								In the past I have worked extensively on <a href="https://cloud.google.com/automl">AutoML</a> through research and product, where my work on <a href="https://en.wikipedia.org/wiki/Neural_architecture_search">Neural Architecture Search (NAS)</a> was an impetus.
                <br>
								<HR>
                Prior to Google Brain, I worked in at the <a href="https://www.isi.edu/research_groups/nlg/home">Information Sciences Institute</a> with <a href="https://kevincrawfordknight.github.io/">Kevin Knight</a> and <a href="https://www.isi.edu/~marcu/">Daniel Marcu</a> on statistical machine translation.
                <br>
                <br>
								In the summer of 2015 I wrote a distributed <a href="https://github.com/isi-nlp/Zoph_RNN">GPU RNN Library</a> in C++/CUDA for machine translation and language modeling. 
								It implemented both data parallelism and pipeline parallelism.
								<HR>
                <br>
                (Last update: January 2022)
                <br>
                <br>

              </p>
              <p style="text-align:center">
                <a href="mailto:barretzoph@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=H-BnRI0AAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/barret_zoph">Twitter</a> &nbsp/&nbsp
								<a href="https://www.linkedin.com/in/barret-zoph-65990543/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/headshot.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/headshot.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
				
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Talks and Media</heading>
              <p>
								<a href="https://www.youtube.com/watch?v=ccBMRryxGog&t=771s&ab_channel=YannicKilcher">Yannic Kilcher's Podcast on Sparsity for Large Language Models</a>
								<br>
								<a href="https://www.youtube.com/watch?v=noZiFhq8GBM&ab_channel=TowardsDataScience">Towards Data Science Podcast on Sparsity for Large Language Models</a>
								<br>
								<a href="https://thedataexchange.media/efficient-scaling-of-language-models/">The Data Exchange Podcast on Efficiently Scaling Large Language Models</a>
								<br>
                <a href="https://www.youtube.com/watch?v=O5Rrv6BvdgE&t=1602s&ab_channel=SamuelAlbanie">ICCV 2019 Neural Architects Workshop Talk</a>
								<br>
								<a href="https://www.youtube.com/watch?v=XDtFXBYpl1w&list=PLkFD6_40KJIwTmSbCv9OVJB3YaO4sFwkX&index=23&t=85s&ab_channel=CALESG-EECS">UC Berkeley Lecture on Deep Reinforcement Learning</a>
								<br>
								<a href="https://www.youtube.com/watch?v=2pbvnxdaKaw&ab_channel=KUISAI"> Ko√ß University Lecture on Transformer Sparsity</a>
								<br>
								<a href="https://www.nytimes.com/2017/11/05/technology/machine-learning-artificial-intelligence-ai.html"> Featured in NYT article on AutoML</a>								
								<br>
								<a href="https://www.technologyreview.com/2017/05/17/151652/why-googles-ceo-is-excited-about-automating-artificial-intelligence/"> Technology Review Article on Google's AutoML/Neural Architecture Search</a>
              </p>
            </td>
          </tr>  
        </tbody></table>
				
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                Representative papers are <span class="highlight">highlighted</span>.
								The * denotes equal author contribution.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
					
				<tr>
					<td class="dash">
						<br>
						<HR>
						<p style="font-size:18px;">Recent</p>
						<HR>
						<br>
					</td>
				</tr>

        <tr bgcolor="#ffffd0">
          <td>
            <p>
              <a href="https://arxiv.org/abs/2202.08906">
              <b>ST-MoE: Designing Scalable and Transferable Sparse Expert Models</b>
              </a>
              <br> 
              <i> <strong>Barret Zoph*</strong>, Irwan Bello*, Sameer Kumar, Nan Du, Yanping Huang, Noam Shazeer, William Fedus*.</i>
							<br>
							[ArXiv 2022] <a href="https://www.youtube.com/watch?v=ccBMRryxGog&t=771s&ab_channel=YannicKilcher">[Yannic Kilcher's Tutorial]</a>
              <p></p>
              <p>
              Sparse Mixture of Experts models suffer from training instabilities and finetuning issues at scale.
              We design improved methods for modeling, pretraining and finetuning sparse models and successfully finetune the largest sparse encoder-decoder model ever trained. 
							State-of-the-art results on many NLP benchmarks like SuperGLUE and ARC Easy / ARC Challenge.
              </p>
            </p>
          </td>
        </tr>
					
        <tr>
          <td>
            <p>
              <a href="https://arxiv.org/abs/2112.06905">
                <b>GLaM: Efficient Scaling of Language Models with Mixture-of-Experts</b>                 
              </a>
              <br>
              <i> Nan Du, Yanping Huang, Andrew M. Dai, Simon Tong, Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun, Yanqi Zhou, Adams Wei Yu, Orhan Firat, <strong>Barret Zoph</strong>, Liam Fedus, Maarten Bosma, Zongwei Zhou, Tao Wang, Yu Emma Wang, Kellie Webster, Marie Pellat, Kevin Robinson, Kathy Meier-Hellstern, Toju Duke, Lucas Dixon, Kun Zhang, Quoc V Le, Yonghui Wu, Zhifeng Chen, Claire Cui.</i>
							<br>
							[ArXiv 2021]
              <p></p>
              <p>
								Successfully train a 1.2 trillion parameter mixture-of-expert language model. It requires 1/3 the energy to train compared to GPT-3, uses half the computational FLOPs for inference and still achieves better zero/one-shot performance on 29 NLP tasks.
              </p>
            </p>
          </td>
        </tr>
					
        <tr bgcolor="#ffffd0">
          <td>
            <p>
              <a href="https://arxiv.org/abs/2108.11353">
                <b>Multi-Task Self-Training for Learning General Representations</b>                 
              </a>
              <br>
              <i> Golnaz Ghiasi*, <strong>Barret Zoph*</strong>, Ekin D Cubuk*, Quoc V Le, Tsung-Yi Lin.</i>
							<br>
							[ICCV 2021]  <font color="red"><strong>(Spotlight Presentation)</strong></font> 
              <p></p>
              <p>
								Introduce multi-task self-training (MuST), which harnesses the knowledge in independent teacher models into a general student model. Scalable multi-task algorithm that works well with unlabeled and partially labeled data.
              </p>
            </p>
          </td>
        </tr>
				
        <tr bgcolor="#ffffd0">
          <td>
            <p>
              <a href="https://arxiv.org/abs/2101.03961">
                <b>Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</b>                 
              </a>
              <br>
              <i> William Fedus*, <strong>Barret Zoph*</strong>, Noam Shazeer.</i>
							<br>
							[ArXiv 2021] <a href="https://www.youtube.com/watch?v=iAR8LkkMMIM&t=109s&ab_channel=YannicKilcher">[Yannic Kilcher's Tutorial]</a>
              <p></p>
              <p>
								Achieved 4-7x pre-training speedups over T5 models and successfully trained the first trillion parameter language model through model sparsity. Achieved state-of-the-art results on NLP benchmarks like ANLI, Natural Questions, WebQuestions and TriviaQA.
              </p>
            </p>
          </td>
        </tr>
				
        <tr>
          <td>
            <p>
              <a href="https://arxiv.org/abs/2107.00057">
                <b>Simple Training Strategies and Model Scaling for Object Detection</b>                 
              </a>
              <br>
              <i> Xianzhi Du*, <strong>Barret Zoph*</strong>, Wei-Chih Hung, Tsung-Yi Lin.</i>
							<br>
							[ArXiv 2021]
              <p></p>
              <p>
								Expand the ResNet-RS work in image classification to object detection and instance segmentation. Finds that significant amount of improvements in object detection are due to training and scaling.
              </p>
            </p>
          </td>
        </tr>

        <tr bgcolor="#ffffd0">
          <td>
            <p>
              <a href="https://arxiv.org/abs/2103.07579">
                <b>Revisiting ResNets: Improved Training and Scaling Strategies</b> 
              </a>
              <br>
              <i>Irwan Bello, William Fedus, Xianzhi Du, Ekin D. Cubuk, Aravind Srinivas, Tsung-Yi Lin, Jonathon Shlens, <strong>Barret Zoph</strong>.</i>
              <br>
              [Neurips 2021]
              <a href="https://github.com/tensorflow/tpu/tree/master/models/official/resnet">[Github]</a>
              <a href="https://cloud.google.com/tpu/docs/tutorials/resnet-rs-2.x">[Google Cloud]</a>
              <a href="https://wandb.ai/wandb_fc/pytorch-image-models/reports/Revisiting-ResNets-Improved-Training-and-Scaling-Strategies--Vmlldzo2NDE3NTM">[Blog posts 1</a>,
              <a href="https://gdude.de/blog/2021-03-15/Revisiting-Resnets">2</a>,
              <a href="https://andlukyane.com/blog/paper-review-resnetsr">3]</a>
							<font color="red"><strong>(Spotlight Presentation)</strong></font>
              <p></p>
              <p>
                Disentangle the impact of architectures vs training and scaling. Reveals that improvements in image classification have been primarily driven by improved training and scaling.
                Identifies general scaling strategies that improve vision models across training setups.
              </p>
            </p>
          </td>
        </tr>

        <tr>
          <td>
            <p>
              <a href="https://arxiv.org/abs/2012.07177">
                <b>Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation</b>                 
              </a>
              <br>
              <i> Golnaz Ghiasi*, Yin Cui*, Aravind Srinivas*, Rui Qian, Tsung-Yi Lin, Ekin D Cubuk, Quoc V. Le, <strong>Barret Zoph</strong>.</i>
							<br>
							[CVPR 2021]  
              <p></p>
              <p>
								Systematically study and scale up a simple copy-paste data augmentation method for instance segmentation.
              </p>
            </p>
          </td>
        </tr>	

        <tr bgcolor="#ffffd0">
          <td>
            <p>
              <a href="https://arxiv.org/abs/2006.06882">
                <b>Rethinking Pre-training and Self-training</b>                 
              </a>
              <br>
              <i> <strong>Barret Zoph*</strong>, Golnaz Ghiasi*, Tsung-Yi Lin*, Yin Cui, Hanxiao Liu, Ekin D Cubuk, Quoc V. Le.</i>
							<br>
							[NeurIPS 2021]  <font color="red"><strong>(Oral Presentation)</strong></font> 
              <p></p>
              <p>
								Improved semi-supervised learning using pseudo labeling for object detection and semantic segmentation. Scaled up results to achieve state-of-the-art on Pascal segmentation.
              </p>
            </p>
          </td>
        </tr>	
				
				<tr>
					<td class="dash">
						<br>
						<HR>
						<p style="font-size:18px;">2019 & 2020</p>
						<HR>
						<br>
					</td>
				</tr>
				
        <tr bgcolor="#ffffd0">
          <td>
            <p>
              <a href="https://arxiv.org/abs/1909.13719">
                <b>Randaugment: Practical automated data augmentation with a reduced search space</b>                 
              </a>
              <br>
              <i> Ekin D Cubuk*, <strong>Barret Zoph*</strong>, Jonathon Shlens, Quoc V. Le.</i>
							<br>
							[NeurIPS 2020]
							<a href="https://www.youtube.com/watch?v=Zzt9i3gDueE&t=1s&ab_channel=HenryAILabs">
                [Henry AI Labs Video]
              </a>
              <p></p>
              <p>
								Significantly simplify and speedup learned data augmentation procedures in computer vision and achieves state-of-the-art ImageNet accuracy.
              </p>
            </p>
          </td>
        </tr>
				
        <tr>
          <td>
            <p>
              <a href="https://arxiv.org/abs/1906.11172">
                <b>Learning data augmentation strategies for object detection</b>                 
              </a>
              <br>
              <i> <strong>Barret Zoph*</strong>, Ekin D Cubuk*, Golnaz Ghiasi, Tsung-Yi Lin, Jonathon Shlens, Quoc V Le.</i>
							<br>
							[ECCV 2020] 
              <p></p>
              <p>
								Expands previous learned data augmenation methods to object detection. Achieves state-of-the-art on COCO object detection and gets strong improvements across a range of models and datasets.
              </p>
            </p>
          </td>
        </tr>
				
        <tr>
          <td>
            <p>
              <a href="https://arxiv.org/abs/1912.02781">
                <b>AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty</b>                 
              </a>
              <br>
              <i> Dan Hendrycks, Norman Mu, Ekin D Cubuk, <strong>Barret Zoph</strong>, Justin Gilmer, Balaji Lakshminarayanan.</i>
							<br>
							[ICLR 2019] 
              <p></p>
              <p>
								Proposes AugMix, which is a data augmentation technique that improves model robustness and uncertainty metrics on several image classification benchmarks.
              </p>
            </p>
          </td>
        </tr>
				
        <tr>
          <td>
            <p>
              <a href="https://arxiv.org/abs/1904.08779">
                <b>Specaugment: A simple data augmentation method for automatic speech recognition</b>                 
              </a>
              <br>
              <i> Daniel S Park, William Chan, Yu Zhang, Chung-Cheng Chiu, <strong>Barret Zoph</strong>, Ekin D Cubuk, Quoc V. Le.</i>
							<br>
							[Interspeed 2019] 
              <p></p>
              <p>
								Introduce SpecAugment, which is a simple data augmentation method for speech recognition. It operates directly on the feature inputs of the neural network and masks blocks of frequency channels and timesteps.
              </p>
            </p>
          </td>
        </tr>

        <tr>
          <td>
            <p>
              <a href="https://arxiv.org/abs/1904.09925">
                <b>Attention Augmented Convolutional Networks</b> 
              </a>
              <br>
              <i> Irwan Bello, <strong>Barret Zoph</strong>, Ashish Vaswani, Jonathon Shlens, Quoc V. Le.</i>
              <br>
              [ICCV 2019]
              <p></p>
              <p>
                Trained <i>the first fully attentional image classifier</i> and showed that self-attention is a competitive replacement to convolutions for image classification.
                Hybrid architectures which combine self-attention and convolution yields sizable improvements on image classification and object detection.
              </p>
            </p>
          </td>
        </tr>
								
        <tr bgcolor="#ffffd0">
          <td>
            <p>
              <a href="https://arxiv.org/abs/1805.09501">
                <b>AutoAugment: Learning Augmentation Policies from Data</b>                 
              </a>
              <br>
              <i> Ekin D. Cubuk*, <strong>Barret Zoph*</strong>, Dandelion Mane, Vijay Vasudevan, Quoc V. Le.</i>
							<br>
							[CVPR 2019] 
              <a href="https://www.youtube.com/watch?v=KHEknuuCz0E&t=3544s&ab_channel=ComputerVisionFoundationVideos">
                [CVPR Talk]
              </a>
              <a href="https://ai.googleblog.com/2018/06/improving-deep-learning-performance.html">
                [Google Blog Post]
              </a>
              <a href="https://www.youtube.com/watch?v=2mNP1iMz7mk&ab_channel=HenryAILabs">
                [Henry AI Labs Tutorial]
              </a>
							 <font color="red"><strong>(Oral Presentation)</strong></font> 
              <p></p>
              <p>
								Introduce AutoAugment, which automatically searches for good data augmentation methods to improve generalization for a given problem and dataset. AutoAugment achieved state-of-the-art accuracy on CIFAR-10, CIFAR-100, SVHN, and ImageNet.
              </p>
            </p>
          </td>
        </tr>
				
				<tr>
					<td class="dash">
						<br>
						<HR>
						<p style="font-size:18px;">2017 & 2018</p>
						<HR>
						<br>
					</td>
				</tr>
				
        <tr>
          <td>
            <p>
              <a href="https://arxiv.org/abs/1802.03268">
                <b>Efficient Neural Architecture Search via Parameter Sharing</b>                 
              </a>
              <br>
              <i> Hieu Pham, Melody Y. Guan, <strong>Barret Zoph</strong>, Quoc V. Le, Jeff Dean.</i>
							<br>
							[ICML 2018] 
              <p></p>
              <p>
								Faster neural architecture search by training and evaluating subgraphs in a larger network.  
              </p>
            </p>
          </td>
        </tr>
			
        <tr>
          <td>
            <p>
              <a href="https://arxiv.org/abs/1712.00559">
                <b>Progressive Neural Architecture Search</b>                 
              </a>
              <br>
              <i> Chenxi Liu, <strong>Barret Zoph</strong>, Maxim Neumann, Jonathon Shlens, Wei Hua, Li-Jia Li, Li Fei-Fei, Alan Yuille, Jonathan Huang, Kevin Murphy.</i>
							<br>
							[ECCV 2018] 
              <p></p>
              <p>
								Develop a new neural network architecture search algorithm using sequential model-based optimization (SMBO). Gets up to 5x speedups over reinforcement learning approaches.
              </p>
            </p>
          </td>
        </tr>
				
        <tr bgcolor="#ffffd0">
          <td>
            <p>
              <a href="https://arxiv.org/abs/1707.07012">
                <b>Learning Transferable Architectures for Scalable Image Recognition</b>                 
              </a>
              <br>
              <i> <strong>Barret Zoph</strong>, Vijay Vasudevan, Jonathan Shlens, Quoc V. Le.</i>
							<br>
							[CVPR 2018]  <font color="red"><strong>(Spotlight Presentation)</strong></font> 
              <p></p>
              <p>
								Learn modular neural network architures through reinforcement learning on CIFAR-10, which also transfer well to ImageNet to obtain state-of-the-art accuracy.
              </p>
            </p>
          </td>
        </tr>
				
        <tr>
          <td>
            <p>
              <a href="https://arxiv.org/abs/1808.02822">
                <b>Backprop evolution</b>                 
              </a>
              <br>
              <i> Maximilian Alber*, Irwan Bello*, <strong>Barret Zoph</strong>, Pieter-Jan Kindermans, Prajit Ramachandran, Quoc Le.</i>
							<br>
							[ArXiv 2018]
              <p></p>
              <p>
								Starting from random or known propagation rules, evolution searches for backpropagation variants that maximize generalization performance.
              </p>
            </p>
          </td>
        </tr>
				
        <tr>
          <td>
            <p>
              <a href="https://arxiv.org/abs/1710.05941">
                <b>Searching for activation functions</b>                 
              </a>
              <br>
              <i> Prajit Ramachandran, <strong>Barret Zoph</strong>, Quoc V. Le.</i>
							<br>
							[ArXiv 2017] 
              <p></p>
              <p>
								Do a large scale exploration of different activation functions and discover interesting trends and new variants that perform well across many computer vision benchmarks.
              </p>
            </p>
          </td>
        </tr>
				
				
        <tr>
          <td>
            <p>
              <a href="https://arxiv.org/abs/1711.02846">
                <b>Intriguing Properties of Adversarial Examples</b>                 
              </a>
              <br>
              <i> Ekin D. Cubuk, <strong>Barret Zoph</strong>, Samuel S. Schoenholz, Quoc V. Le.</i>
							<br>
							[ArXiv 2017] 
              <p></p>
              <p>
								Argue that adversarial examples arise from inherent uncertainty that neural networks have about their predictions. Furthermore, we study if we can find good neural network architectures that are more adversarially robust than others.
              </p>
            </p>
          </td>
        </tr>
				
        <tr>
          <td>
            <p>
              <a href="https://arxiv.org/abs/1709.07417">
                <b>Neural Optimizer Search with Reinforcement Learning</b>                 
              </a>
              <br>
              <i> Irwan Bello*, <strong>Barret Zoph*</strong>, Vijay Vasudevan, Quoc V. Le.</i>
							<br>
							[ICML 2017]
              <p></p>
              <p>
								Automated discovery of optimization methods by generating update rules with an RL-trained controller. Discovered two new optimizers and learning rate schedules which experimentally lead to faster convergence in image classification and machine translation.
              </p>
            </p>
          </td>
        </tr>
				
				
        <tr bgcolor="#ffffd0">
          <td>
            <p>
              <a href="https://arxiv.org/abs/1611.01578">
                <b>Neural Architecture Search with Reinforcement Learning</b>                 
              </a>
              <br>
              <i> <strong>Barret Zoph</strong>, Quoc V. Le.</i>
							<br>
							[ICLR 2017] 
              <a href="https://ai.googleblog.com/2017/05/using-machine-learning-to-explore.html">
                [Google Blog Post]
              </a>
              <a href="https://en.wikipedia.org/wiki/Neural_architecture_search">
                [Wikipedia]
              </a>
							<font color="red"><strong>(Oral Presentation)</strong></font> 
              <p></p>
              <p>
								Use reinforcement learning to automatically design good neural network architectures for computer vision and language modeling.
              </p>
            </p>
          </td>
        </tr>
				
				<tr>
					<td class="dash">
						<br>
						<HR>
						<p style="font-size:18px;">2015 & 2016</p>
						<HR>
						<br>
					</td>
				</tr>
				
        <tr>
          <td>
            <p>
              <a href="https://arxiv.org/abs/1604.02201">
                <b>Transfer Learning for Low-Resource Neural Machine Translation</b>                 
              </a>
              <br>
              <i> <strong>Barret Zoph</strong>, Deniz Yuret, Jonathan May, Kevin Knight.</i>
							<br>
							[EMNLP 2016]
              <p></p>
              <p>
								Develope a transfer learning algorithm to improve low resource machine translation.
              </p>
            </p>
          </td>
        </tr>
								
        <tr>
          <td>
            <p>
              <a href="https://aclanthology.org/N16-1145.pdf">
                <b>Simple, Fast Noise-Contrastive Estimation for Large RNN Vocabularies</b>                 
              </a>
              <br>
              <i> <strong>Barret Zoph*</strong>, Ashish Vaswani*, Jonathan May, Kevin Knight.</i>
							<br>
							[NAACL 2016]
              <p></p>
              <p>
								 Design an algorithm to train large vocabulary language models efficiently on GPUs using Noise Contrastive Estimation (NCE).
              </p>
            </p>
          </td>
        </tr>
				
        <tr>
          <td>
            <p>
              <a href="https://arxiv.org/abs/1601.00710">
                <b>Multi-Source Neural Translation</b>                 
              </a>
              <br>
              <i> <strong>Barret Zoph</strong>, Kevin Knight.</i>
							<br>
							[NAACL 2016]  <font color="red"><strong>(Oral Presentation)</strong></font>
              <p></p>
              <p>
								Built a new neural architecture than can take in n translations in order to produce a better translation in the n+1 language. 
              </p>
            </p>
          </td>
        </tr>

        <tr bgcolor="#ffffd0">
          <td>
            <p>
              <a href="https://aclanthology.org/D15-1105.pdf">
                <b>How Much Information Does a Human Translator Add to the Original?</b>                 
              </a>
              <br>
              <i> <strong>Barret Zoph</strong>, Marjan Ghazvininejad, Kevin Knight.</i>
							<br>
							[EMNLP 2015]  
              <a href="https://www.microsoft.com/en-us/research/video/how-much-information-does-a-human-translator-add-to-the-original-and-multi-source-neural-translation/">
                [Microsoft Research Talk]
              </a>
              <a href="https://vimeo.com/160938206">
                [EMNLP Talk]
              </a>
							<font color="red"><strong>(Oral Presentation)</strong></font>
              <p></p>
              <p>
								How much information does a human translator add to an original text? We provide a bound using compression and develop new text compression algorithms and a benchmark.
              </p>
            </p>
          </td>
        </tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right"><font size="2">
                <a href="http://www.cs.berkeley.edu/~barron/">(website template credits)</a>
                </font>
              </p>
            </td>
          </tr>
        </table>

      </td>
    </tr>
  </table>
</body>

</html>